{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBcQElcAYWuJ"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet34, ResNet34_Weights\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "SAVE_PATH='/content/drive/MyDrive/DR_grading/trained_models'\n",
        "model=resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "# 修改全连接层的输出\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 6)\n",
        "\n",
        "model.load_state_dict(torch.load(SAVE_PATH+'/Resnet34_4epoch.pt'))\n",
        "model.eval()\n",
        "img_path='/content/drive/MyDrive/dataset/DDR-dataset/DR_grading/test/007-2523-100.jpg'\n",
        "with torch.no_grad():\n",
        "   img = Image.open(img_path) # fp -文件名 (字符串)，pathlib.Path对象或文件对象\n",
        "   w, h = img.size\n",
        "   slide=min(h,w)\n",
        "   center_cropper=torchvision.transforms.CenterCrop(slide)\n",
        "   cropped_img = center_cropper(img)\n",
        "   resizer=torchvision.transforms.Resize((512,512))\n",
        "   res_img=resizer(cropped_img)\n",
        "   totensor=torchvision.transforms.ToTensor()\n",
        "   img_tensor=torch.unsqueeze(totensor(res_img) ,dim=0)\n",
        "   prediction=model(img_tensor).sigmoid()\n",
        "   sum=torch.cumsum(prediction,dim=0)\n",
        "   real_pre=torch.argmax(sum).cpu().numpy()\n",
        "   print(real_pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Ee3mU5jfxv",
        "outputId": "79ea3600-ec7e-48c3-9268-9b2718af1f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZiSTKadYFq3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# import pytorch_lightning as pl\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# os.chdir('/content/drive/MyDrive/DRseg')\n",
        "from pprint import pprint\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rudy39moYpEy"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "DATASET_PATH='/content/drive/MyDrive/dataset/DDR-dataset/DR_grading'\n",
        "CKPT_PATH=\"/content/drive/MyDrive/DRseg/SAVE/\"\n",
        "INPUT_SIZE=1024\n",
        "# this is running on server\n",
        "class GRADData(Dataset):  # 继承Dataset这个类\n",
        "    def __init__(self,mode):\n",
        "        self.img_path = DATASET_PATH+'/'+mode\n",
        "        self.img_names = os.listdir(self.img_path)\n",
        "        if mode=='train':\n",
        "         self.label_path = DATASET_PATH+'/'+mode+'.txt'\n",
        "        else:\n",
        "         self.label_path = DATASET_PATH+'/valid.txt'\n",
        "        self.label_dict = {}\n",
        "        fopen = open(self.label_path)\n",
        "        for line in fopen.readlines():\n",
        "          line = str(line).replace(\"\\n\",\"\") #remove \\n\n",
        "          self.label_dict[line.split(' ',1)[0]] = line.split(' ',1)[1]\n",
        "        fopen.close()\n",
        "        self.resizer=torchvision.transforms.Resize((INPUT_SIZE,INPUT_SIZE))\n",
        "        self.totensor=torchvision.transforms.ToTensor()\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "    def __getitem__(self, item):\n",
        "        img_name= self.img_names[item]\n",
        "        img_path= os.path.join(self.img_path, self.img_names[item])\n",
        "        img = Image.open(img_path) # fp -文件名 (字符串)，pathlib.Path对象或文件对象\n",
        "        label = self.label_dict[img_name]\n",
        "        w, h = img.size\n",
        "\n",
        "        slide=min(h,w)\n",
        "        center_cropper=torchvision.transforms.CenterCrop(slide)\n",
        "        cropped_img = center_cropper(img)\n",
        "\n",
        "        res_img=self.resizer(cropped_img)\n",
        "\n",
        "        lr_flipped_img =self.totensor( self.resizer(cropped_img.transpose(Image.FLIP_LEFT_RIGHT) )) # 水平翻转\n",
        "        td_flipped_img =self.totensor( self.resizer(cropped_img.transpose(Image.FLIP_TOP_BOTTOM) )) # 竖直翻转\n",
        "        lr_td_flipped_img =self.totensor( self.resizer(cropped_img.transpose(Image.FLIP_TOP_BOTTOM).transpose(Image.FLIP_LEFT_RIGHT) )) # 水平+竖直翻转\n",
        "        imgs=[self.totensor(self.resizer(cropped_img))]+[lr_flipped_img]+[td_flipped_img]+[ lr_td_flipped_img ]\n",
        "\n",
        "        img_tensor=torch.stack(tuple(imgs))\n",
        "        label_num=int(label)\n",
        "        label_tensor=torch.zeros((4,1),dtype=torch.long)\n",
        "        label_tensor[:,0]=label_num\n",
        "        return img_tensor,label_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ywEAF8NX5K5",
        "outputId": "ea22e938-4226-47c8-bbf1-79adb3132c37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load net\n",
            "load success\n",
            "begin 0 epoch\n",
            "begin 1 epoch\n",
            "begin 2 epoch\n",
            "begin 3 epoch\n",
            "begin 4 epoch\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet34, ResNet34_Weights\n",
        "from torch import nn\n",
        "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "BATCH_SIZE=1\n",
        "SAVE_PATH='/content/drive/MyDrive/DR_grading/trained_models'\n",
        "# Using pretrained weights:\n",
        "model=resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "# 修改全连接层的输出\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 6)\n",
        "model=model.cuda()\n",
        "data = GRADData('train')\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
        "grad_dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
        "\n",
        "EPOCH = 5\n",
        "print('load net')\n",
        "# model.load_state_dict(torch.load(SAVE_PATH+'/Resnet34_9epoch.pt'))\n",
        "print('load success')\n",
        "for epoch in range(EPOCH):\n",
        "    print('begin {} epoch'.format(epoch))\n",
        "    model.train() # model.train() 将 self.training = True，model.eval() 将 self.training = False，\n",
        "    # 所以即便训练与测试共用一个模型，也能通过 self.training 来区分现在属于训练还是测试。它们用于切换模式。\n",
        "    for i, (img, label) in enumerate(grad_dataloader):\n",
        "\n",
        "        img = img.reshape(4*BATCH_SIZE,3,INPUT_SIZE,INPUT_SIZE)\n",
        "        img=img.cuda()\n",
        "        label = label.reshape(4*BATCH_SIZE).cuda()\n",
        "        predict_label = model(img)# 前向传播 forward是在__call__中调用的，而__call__函数是在类的对象使用‘()’时被调用。\n",
        "\n",
        "        loss = loss_func(predict_label, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    torch.save(model.state_dict(), SAVE_PATH+'/Resnet34_{}epoch.pt'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxVvcgbDnHEF",
        "outputId": "d21248b8-b854-4c8c-88fb-be1183de382a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.]])\n",
            "tensor([4, 1, 2])\n",
            "tensor(0.9048)\n"
          ]
        }
      ],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "# input = torch.randn(3, 5, requires_grad=True)\n",
        "input=torch.tensor([[0.,0,0,0,1],\n",
        "                    [0,1,0,0,0],\n",
        "                    [0,0,1,0,0]])\n",
        "print(input)\n",
        "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "target=torch.tensor([4,1,2])\n",
        "print(target)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "\n",
        " # Example of target with class probabilities\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5).softmax(dim=1)\n",
        "output = loss(input, target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfC6ZcYIjoGI",
        "outputId": "b7f8fbba-5607-452b-d373-710d5563ce55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load net\n",
            "------Weighted------\n",
            "Weighted precision 1.0\n",
            "Weighted recall 0.9399477806788512\n",
            "Weighted f1-score 0.9690444145356663\n",
            "------Macro------\n",
            "Macro precision 0.3333333333333333\n",
            "Macro recall 0.3133159268929504\n",
            "Macro f1-score 0.3230148048452221\n",
            "------Micro------\n",
            "Micro precision 0.9399477806788512\n",
            "Micro recall 0.9399477806788512\n",
            "Micro f1-score 0.9399477806788512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet34, ResNet34_Weights\n",
        "from torch import nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score\n",
        "import numpy as np\n",
        "SAVE_PATH='/content/drive/MyDrive/DR_grading/trained_models'\n",
        "data = GRADData('test')\n",
        "BATCH_SIZE=1\n",
        "grad_dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, drop_last=True)\n",
        "model=resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "# 修改全连接层的输出\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 6)\n",
        "model=model.cuda()\n",
        "\n",
        "epoches='4'\n",
        "print('load net')\n",
        "model.load_state_dict(torch.load(SAVE_PATH+'/Resnet34_'+epoches+'epoch.pt'))\n",
        "model.eval()\n",
        "y_true=[0]\n",
        "y_pred=[0]\n",
        "with torch.no_grad():\n",
        " for i, (img, label) in enumerate(grad_dataloader):\n",
        "   img=torch.squeeze(img,dim=0).cuda()\n",
        "   prediction=model(img).sigmoid()\n",
        "   sum=torch.cumsum(prediction,dim=0)[3]\n",
        "   real_pre=torch.argmax(sum).cpu().numpy()\n",
        "   y_true=np.hstack((y_true,(torch.argmax(label[0]).numpy())))\n",
        "   y_pred=np.hstack((y_pred,real_pre))\n",
        "\n",
        "C=confusion_matrix(y_true, y_pred)\n",
        "print('------Weighted------')\n",
        "print('Weighted precision', precision_score(y_true, y_pred, average='weighted'))\n",
        "print('Weighted recall', recall_score(y_true, y_pred, average='weighted'))\n",
        "print('Weighted f1-score', f1_score(y_true, y_pred, average='weighted'))\n",
        "print('------Macro------')\n",
        "print('Macro precision', precision_score(y_true, y_pred, average='macro'))\n",
        "print('Macro recall', recall_score(y_true, y_pred, average='macro'))\n",
        "print('Macro f1-score', f1_score(y_true, y_pred, average='macro'))\n",
        "print('------Micro------')\n",
        "print('Micro precision', precision_score(y_true, y_pred, average='micro'))\n",
        "print('Micro recall', recall_score(y_true, y_pred, average='micro'))\n",
        "print('Micro f1-score', f1_score(y_true, y_pred, average='micro'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}